#VAR: ansible_managed | comment :VAR#

#################################################################
#                            DEFAULTS                           #
#################################################################

x-defaults: &defaults
  x-dummy: ""
  # Putting the anchor in this file ensures it's a valid YAML file for Renovate Bot
  #VAR: lookup('ansible.builtin.file', 'files/docker-compose-defaults.yml',) | indent(width=2) :VAR#

x-healthcheck-mongo: &healthcheck-mongo
  healthcheck:
    test:
      [
        "CMD-SHELL",
        "mongosh --quiet localhost --eval 'quit(db.runCommand({ ping: 1 }).ok ? 0 : 1)'",
      ]
    interval: 30s
    timeout: 10s
    retries: 5

#################################################################
#                            SERVICES                           #
#################################################################
services:
  # =========================
  # =         PROXY         =
  # =========================
  # Having 2 reverse proxies (1 on host network and 1 on bridge network)
  # allows to have the real client IP's available inside the bridged
  # Caddy instance (using PROXY protocol). In case you would only have
  # a single reverse proxy on the host network, you would loose all the convenience
  # of using Docker networks.
  nginx:
    <<: *defaults
    image: docker.io/library/nginx:alpine
    container_name: nginx
    network_mode: host
    volumes:
      - ./nginx/default.conf:/etc/nginx/nginx.conf:ro

  caddy:
    <<: *defaults
    build: ./caddy
    container_name: caddy
    ports:
      - 127.0.0.1:2080:80
      - 127.0.0.1:2443:443
    networks:
      - caddy
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - ./caddy/configs:/etc/caddy/configs:ro
      - caddy-config:/config
      - caddy-data:/data
    environment:
      TZ: "#VAR: general_timezone :VAR#"

  # ==========================
  # =      DNS - BLOCKY      =
  # ==========================
  blocky:
    <<: *defaults
    image: ghcr.io/0xerr0r/blocky:latest
    container_name: blocky
    user: "#VAR: ansible_real_user_id :VAR#:#VAR: ansible_real_group_id :VAR#"
    networks:
      - caddy
    ports:
      - "53:53/tcp" # DNS TCP
      - "53:53/udp" # DNS UDP
    volumes:
      - ./blocky/config.txt:/app/config.yml:ro

  # ===========================
  # =    UNIFI NETWORK APP    =
  # ===========================
  unifi-network-app:
    <<: *defaults
    image: lscr.io/linuxserver/unifi-network-application:latest
    container_name: unifi-network-app
    environment:
      TZ: "#VAR: general_timezone :VAR#"
      PUID: "1000"
      PGID: "1000"
      MEM_LIMIT: "1024"
      MEM_STARTUP: "1024"
      MONGO_HOST: unifi-mongodb
      MONGO_PORT: "27017"
      MONGO_USER: "#VAR: app_unifi_mongodb_user :VAR#"
      MONGO_PASS: "#VAR: app_unifi_mongodb_password :VAR#"
      MONGO_DBNAME: unifi
    volumes:
      - "#VAR: general_path_appdata :VAR#/unifi/network-app/config:/config"
    ports:
      - "10001:10001/udp" # Required for AP discovery
      - "8080:8080" # Required for device communication
    networks:
      - caddy
      - unifi
    depends_on:
      unifi-mongodb:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G

  unifi-mongodb: # NOTE: MongoDB 5.0+ requires AVX!
    <<: [*defaults, *healthcheck-mongo]
    # "Version 8.1 and newer supports up to MongoDB 7.0."
    # See release notes at https://www.ui.com/download/releases/network-server
    build: ./unifi/mongodb
    container_name: unifi-mongodb
    environment:
      TZ: "#VAR: general_timezone :VAR#"
    networks:
      - unifi
    volumes:
      - "#VAR: general_path_appdata :VAR#/unifi/mongodb/data:/data/db"
      - unifi-mongodb-dump:/backup
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G

  # =========================
  # =         BACKUP        =
  # =========================
  github-backup:
    <<: *defaults
    image: docker.io/jenswbe/github-backup:latest
    container_name: github-backup
    restart: "no" # Will be called by systemd timer
    volumes:
      - ./github-backup/config.yml:/config.yml
      - github-backup:/backup
    environment:
      - "TZ=#VAR: general_timezone :VAR#"

  borgmatic:
    <<: *defaults
    image: ghcr.io/borgmatic-collective/borgmatic:2.0
    container_name: borgmatic
    cap_add:
      - SYS_ADMIN # Required for borg mount
    volumes:
      # Backup locations
      - "github-backup:/mnt/source/github-backup/backup:ro"
      - "unifi-mongodb-dump:/mnt/source/unifi/mongodb:ro"
      # Config and cache
      - "./borgmatic/borgmatic.d/config.yaml:/etc/borgmatic.d/config.yaml"
      - "./borgmatic/ssh/BorgHost:/root/.ssh/BorgHost"
      - "./borgmatic/ssh/known_hosts:/root/.ssh/known_hosts"
      - "#VAR: general_path_appdata :VAR#/borgmatic/borgmatic/config:/root/.config/borg"
      - "#VAR: general_path_appdata :VAR#/borgmatic/borgmatic/cache:/root/.cache/borg"
      - "#VAR: general_path_appdata :VAR#/borgmatic/borgmatic/restore:/mnt/restore"
    devices:
      - "/dev/fuse:/dev/fuse" # Required for borg mount
    environment:
      TZ: "#VAR: general_timezone :VAR#"
      BACKUP_CRON: "0 3 * * *"
      BORG_PASSPHRASE: "#VAR: app_borgmatic_borg_passphrase :VAR#"
      BORG_HOSTNAME_IS_UNIQUE: "yes" # Automatically removes stale locks
      BORG_HOST_ID: "#VAR: ansible_hostname :VAR#"
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 4G

#################################################################
#                            NETWORKS                           #
#################################################################
networks:
  caddy:
    name: caddy

  unifi:
    name: unifi

#################################################################
#                            VOLUMES                            #
#################################################################
volumes:
  caddy-config:
  caddy-data:
  github-backup:
  unifi-mongodb-dump:
